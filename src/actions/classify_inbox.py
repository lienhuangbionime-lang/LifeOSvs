import os
import json
import re
import glob
import datetime
import frontmatter
import requests

# å®šç¾©è·¯å¾‘
INBOX_DIR = "data/inbox"
PROJECTS_DIR = "data/projects"
LIFE_DIR = "data/life"

# Webhook
ZAPIER_TASK_WEBHOOK = os.getenv("ZAPIER_TASK_WEBHOOK")

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

def append_to_log(filepath, date, content, source_uuid):
    """
    é€šç”¨å¯«å…¥å‡½æ•¸ï¼šå°‡å…§å®¹ Append åˆ°æŒ‡å®šçš„ Markdown æª”æ¡ˆ
    """
    header = f"\n\n### {date} (Ref: {source_uuid})\n"
    
    # ç°¡å–®çš„é˜²é‡è¤‡æª¢æŸ¥ (è®€å–æœ€å¾Œ 1000 å­—ï¼Œçœ‹æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ UUID)
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            # è®€å–æª”å°¾
            try:
                f.seek(0, 2)
                size = f.tell()
                f.seek(max(size - 2000, 0), 0)
                tail = f.read()
                if source_uuid in tail:
                    print(f"Skipping duplicate entry for {filepath}")
                    return
            except:
                pass # æ–°æª”æ¡ˆæˆ–è®€å–éŒ¯èª¤ç›´æ¥å¯«å…¥

    with open(filepath, 'a+', encoding='utf-8') as f:
        f.write(header)
        f.write(content.strip())
    
    print(f"ğŸ“ Appended to {os.path.basename(filepath)}")

def extract_tasks(content):
    """å¾æ—¥è¨˜å…§å®¹ä¸­æŠ“å–å¾…è¾¦äº‹é …"""
    tasks = []
    # æ¨¡å¼ A: Tomorrow's MIT
    mit_match = re.search(r"Tomorrow's MIT.*?(\n(?:[-*].*?|\s*)*)(?=\n#|\n\n|$)", content, re.IGNORECASE | re.DOTALL)
    if mit_match:
        lines = mit_match.group(1).strip().split('\n')
        for line in lines:
            clean_line = re.sub(r"^[-*]\s*", "", line).strip()
            if clean_line: tasks.append(clean_line)

    # æ¨¡å¼ B: Checkbox [ ]
    checkboxes = re.findall(r"-\s*\[\s*\]\s*(.*)", content)
    tasks.extend(checkboxes)
    return list(set(tasks))

def send_to_zapier(tasks, date):
    if not ZAPIER_TASK_WEBHOOK: return
    for task in tasks:
        try:
            requests.post(ZAPIER_TASK_WEBHOOK, json={"title": task, "date": date, "source": "LifeOS"})
        except Exception as e:
            print(f"âŒ Failed to send task: {e}")

def process_inbox_files():
    ensure_dir(PROJECTS_DIR)
    ensure_dir(LIFE_DIR)
    
    # è®€å– Inbox æ‰€æœ‰ .md
    files = glob.glob(os.path.join(INBOX_DIR, "*.md"))
    if not files:
        print("No files to classify.")
        return

    for filepath in files:
        try:
            # 1. è®€å– Markdown & Frontmatter
            post = frontmatter.load(filepath)
            content = post.content
            metadata = post.metadata
            
            # å–å¾—é—œéµå…ƒæ•¸æ“š
            uuid_str = metadata.get('uuid', 'unknown')
            date_str = metadata.get('date', datetime.datetime.now().strftime('%Y-%m-%d'))
            # ç¢ºä¿ date_str æ˜¯å­—ä¸² (æœ‰æ™‚ YAML æœƒè§£ææˆ datetime ç‰©ä»¶)
            if isinstance(date_str, datetime.date):
                date_str = date_str.strftime('%Y-%m-%d')
            
            # å˜—è©¦è®€å– Sidecar JSON ä»¥ç²å¾—æ›´ç²¾æº–çš„ tags
            json_path = filepath.replace('.md', '.json')
            tags = metadata.get('tags', [])
            if os.path.exists(json_path):
                with open(json_path, 'r', encoding='utf-8') as jf:
                    sidecar = json.load(jf)
                    if 'analysis' in sidecar and 'tags' in sidecar['analysis']:
                        # åˆä½µ tags
                        ai_tags = sidecar['analysis']['tags']
                        if isinstance(ai_tags, list):
                            tags.extend(ai_tags)
            
            # å»é‡ä¸¦æ­£è¦åŒ– Tags
            tags = list(set([t.lower().replace('#', '') for t in tags if isinstance(t, str)]))

            # --- è·¯ç”±é‚è¼¯ (Routing Logic) ---

            # A. Life Track (å…¨é‡å‚™ä»½)
            # æŒ‰å¹´ä»½æ­¸æª”ï¼Œä¾‹å¦‚ data/life/2026_log.md
            year = date_str[:4]
            life_file = os.path.join(LIFE_DIR, f"{year}_log.md")
            append_to_log(life_file, date_str, content, uuid_str)

            # B. Project Track (å°ˆæ¡ˆåˆ†æµ)
            # å¦‚æœ Tag ç¬¦åˆç¾æœ‰å°ˆæ¡ˆï¼Œæˆ–çœ‹èµ·ä¾†åƒå°ˆæ¡ˆåï¼Œå‰‡å¯«å…¥
            # é€™è£¡ç°¡å–®åˆ¤å®šï¼šåªè¦æœ‰ Tagï¼Œå°±è¦–ç‚ºä¸€å€‹ Topic/Project
            for tag in tags:
                # éæ¿¾æ‰é€šç”¨ Tags
                if tag in ['journal', 'log', 'daily', 'life']:
                    continue
                
                # æª”åæ¸…ç† (é¿å…éæ³•å­—å…ƒ)
                safe_tag = re.sub(r'[\\/*?:"<>|]', "", tag).title()
                project_file = os.path.join(PROJECTS_DIR, f"{safe_tag}.md")
                
                # å¯«å…¥å°ˆæ¡ˆæ—¥èªŒ
                append_to_log(project_file, date_str, content, uuid_str)

            # C. Task Extraction
            tasks = extract_tasks(content)
            if tasks:
                print(f"Found {len(tasks)} tasks via regex.")
                #send_to_zapier(tasks, date_str)

        except Exception as e:
            print(f"Error classifying {filepath}: {e}")

if __name__ == "__main__":
    process_inbox_files()
